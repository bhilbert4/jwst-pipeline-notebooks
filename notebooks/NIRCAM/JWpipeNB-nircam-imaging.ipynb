{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095a295c",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_header.png' alt=\"stsci_logo\" width=\"900px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393e357-9d9d-4516-b28d-4d335fad33a0",
   "metadata": {},
   "source": [
    "#  NIRCam Imaging Pipeline Notebook\n",
    "\n",
    "**Authors**: B. Hilbert, based on the NIRISS imaging notebook by R. Diaz<br>\n",
    "**Last Updated**: September 5, 2024<br>\n",
    "**Pipeline Version**: 1.15.1 (Build 11.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2029f",
   "metadata": {},
   "source": [
    "**Purpose**:\n",
    "\n",
    "This notebook provides a framework for processing generic Near-Infrared\n",
    "Camera (NIRCam) Imaging data through all three James Webb Space Telescope\n",
    "(JWST) pipeline stages.  Data is assumed to be located in a folder structure\n",
    "following the paths set up below. It should not be necessary to edit\n",
    "any cells other than in the [Configuration](#1.-Configuration) section unless\n",
    "modifying the standard pipeline processing options.\n",
    "\n",
    "**Data**:\n",
    "This example is set up to use an example dataset is from\n",
    "[Program ID](https://www.stsci.edu/jwst/science-execution/program-information)\n",
    "2739 (PI: Pontoppidan) which is a Cycle 1 Outreach program. \n",
    "We focus on the data from Observation 002, in which M-16, or the\n",
    "\"Pillars of Creation\" were observed.\n",
    "\n",
    "Example input data to use will be downloaded automatically unless\n",
    "disabled (i.e., to use local files instead).\n",
    "\n",
    "**JWST pipeline version and CRDS context** This notebook was written for the\n",
    "calibration pipeline version given above. It sets the CRDS context\n",
    "to use the most recent version available in the JWST Calibration\n",
    "Reference Data System (CRDS). If you use different pipeline versions or\n",
    "CRDS context, please read the relevant release notes\n",
    "([here for pipeline](https://github.com/spacetelescope/jwst),\n",
    "[here for CRDS](https://jwst-crds.stsci.edu/)) for possibly relevant\n",
    "changes.<BR>\n",
    "\n",
    "**Updates**:\n",
    "This notebook is regularly updated as improvements are made to the\n",
    "pipeline. Find the most up to date version of this notebook at:\n",
    "https://github.com/spacetelescope/jwst-pipeline-notebooks/\n",
    "\n",
    "**Recent Changes**:<br>\n",
    "Sept 5, 2024: original notebook created<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5291c2f1",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Configuration](#Configuration) \n",
    "2. [Package Imports](#Package-Imports)\n",
    "3. [Demo Mode Setup (ignore if not using demo data)](#Demo-Mode-Setup-(ignore-if-not-using-demo-data))\n",
    "4. [Directory Setup](#Directory-Setup)\n",
    "5. [Detector1 Pipelineg](#Detector1-Pipeline)\n",
    "6. [Image2 Pipeline](#Image2-Pipeline)\n",
    "7. [Image3 Pipeline](#Image3-Pipeline)\n",
    "8. [Visualize the resampled images](#Visualize-the-resampled-images)\n",
    "9. [Resample both filters onto the same pixel grid](#Same-pixel-grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd07d7",
   "metadata": {},
   "source": [
    "<a id='Configuration'></a>\n",
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fe58d-f3c5-4aec-8e14-5323eaf786bd",
   "metadata": {},
   "source": [
    "------------------\n",
    "Set basic configuration for runing notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a649d-a0d2-4e3f-ab6d-cf8c26e6ce1d",
   "metadata": {},
   "source": [
    "#### Install dependencies and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c4ca9",
   "metadata": {},
   "source": [
    "To make sure that the pipeline version is compatabile with the steps\n",
    "discussed below and the required dependencies and packages are installed,\n",
    " you can create a fresh conda environment and install the provided\n",
    "`requirements.txt` file:\n",
    "```\n",
    "conda create -n nircam_imaging_pipeline python=3.11\n",
    "conda activate nircam_imaging_pipeline\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Set the basic parameters to use with this notebook. These will affect\n",
    "what data is used, where data is located (if already in disk), and\n",
    "pipeline modules run in this data. The list of parameters are:\n",
    "\n",
    "* demo_mode\n",
    "* directories with data\n",
    "* pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic import necessary for configuration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb14e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that <code>demo_mode</code> must be set appropriately below.\n",
    "</div>\n",
    "\n",
    "Set <code>demo_mode = True </code> to run in demonstration mode. In this\n",
    "mode this notebook will download example data from the Barbara A.\n",
    "Mikulski Archive for Space Telescopes (MAST) and process it through the\n",
    "pipeline. This will all happen in a local directory unless modified\n",
    "in [Section 3](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data))\n",
    "below. \n",
    "\n",
    "Set <code>demo_mode = False</code> if you want to process your own data\n",
    "that has already been downloaded and provide the location of the data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for demo_mode, channel, band, data mode directories, and \n",
    "# processing steps.\n",
    "\n",
    "# -----------------------------Demo Mode---------------------------------\n",
    "demo_mode = True\n",
    "\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode using online example data!')\n",
    "\n",
    "# --------------------------User Mode Directories------------------------\n",
    "# If demo_mode = False, look for user data in these paths\n",
    "if not demo_mode:\n",
    "    # Set directory paths for processing specific data; these will need\n",
    "    # to be changed to your local directory setup (below are given as\n",
    "    # examples)\n",
    "    user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "    # Point to where science observation data are\n",
    "    # Assumes uncalibrated data in <sci_dir>/uncal/ and results in stage1,\n",
    "    # stage2, stage3 directories\n",
    "    sci_dir = os.path.join(user_home_dir, 'PID3729/obs001/')\n",
    "\n",
    "# --------------------------Set Processing Steps--------------------------\n",
    "# Individual pipeline stages can be turned on/off here.  Note that a later\n",
    "# stage won't be able to run unless data products have already been\n",
    "# produced from the prior stage.\n",
    "\n",
    "# Science processing\n",
    "dodet1 = True  # calwebb_detector1\n",
    "doimage2 = True  # calwebb_image2\n",
    "doimage3 = True  # calwebb_image3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070079a",
   "metadata": {},
   "source": [
    "### Set CRDS context and server\n",
    "Before importing <code>CRDS</code> and <code>JWST</code> modules, we need\n",
    "to configure our environment. This includes defining a CRDS cache\n",
    "directory in which to keep the reference files that will be used by the\n",
    "calibration pipeline.\n",
    "\n",
    "If the root directory for the local CRDS cache directory has not been set\n",
    "already, it will be set to create one in the home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------Set CRDS context and paths----------------------\n",
    "\n",
    "# Set CRDS context (if overriding to use a specific version of reference\n",
    "# files; leave commented out to use latest reference files by default)\n",
    "#%env CRDS_CONTEXT  jwst_1254.pmap\n",
    "\n",
    "# Check whether the local CRDS cache directory has been set.\n",
    "# If not, set it to the user home directory\n",
    "if (os.getenv('CRDS_PATH') is None):\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n",
    "# Check whether the CRDS server URL has been set.  If not, set it.\n",
    "if (os.getenv('CRDS_SERVER_URL') is None):\n",
    "    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "\n",
    "# Echo CRDS path in use\n",
    "print(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\n",
    "print(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575588c8",
   "metadata": {},
   "source": [
    "<a id='Package-Imports'></a>\n",
    "## 2. Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entire available screen width for this notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f7f54-ff98-428b-9fa9-b39c50210c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic system utilities for interacting with files\n",
    "# ----------------------General Imports------------------------------------\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Numpy for doing calculations\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------Astroquery Imports--------------------------------\n",
    "# ASCII files, and downloading demo files\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# For visualizing images\n",
    "from jdaviz import Imviz\n",
    "\n",
    "# Astropy routines for visualizing detected sources:\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# for JWST calibration pipeline\n",
    "import jwst\n",
    "import crds\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "\n",
    "# JWST pipeline utilities\n",
    "from asdf import AsdfFile\n",
    "from jwst import datamodels\n",
    "from jwst.associations import asn_from_list  # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n",
    "\n",
    "# Echo pipeline version and CRDS context in use\n",
    "print(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\n",
    "print(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844d476-f8b3-4c24-9c79-091d6016314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer to keep track of runtime\n",
    "time0 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8050f",
   "metadata": {},
   "source": [
    "<a id='Demo-Mode-Setup-(ignore-if-not-using-demo-data)'></a>\n",
    "## 3. Demo Mode Setup (ignore if not using demo data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f182c-cf63-4f82-b5a7-0285be9c21e3",
   "metadata": {},
   "source": [
    "------------------\n",
    "If running in demonstration mode, set up the program information to\n",
    "retrieve the uncalibrated data automatically from MAST using\n",
    "[astroquery](https://astroquery.readthedocs.io/en/latest/mast/mast.html).\n",
    "MAST allows for flexibility of searching by the proposal ID and the\n",
    "observation ID instead of just filenames.<br>\n",
    "\n",
    "For illustrative purposes, we focus on data taken using the NIRCam\n",
    "[F200W and F444W filters](https://jwst-docs.stsci.edu/jwst-near-infrared-camera/nircam-instrumentation/nircam-filters)\n",
    "and start with uncalibrated data products. The files are named\n",
    "`jw02739001002_02105_0000<dither>_nrc<det>_uncal.fits`, where *dither* refers to the\n",
    " dither step number, and *det* is the detector name. \n",
    " \n",
    "More information about the JWST file naming conventions can be found at:\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d595f1e-2590-4f01-bb92-13bb43a22b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the program information and paths for demo program\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode and will download example data from MAST!')\n",
    "    program = '02739'\n",
    "    sci_observtn = \"001\"\n",
    "    \n",
    "    data_dir = os.path.join('.', 'nrc_im_demo_data')\n",
    "    download_dir = data_dir\n",
    "    sci_dir = os.path.join(data_dir, 'Obs' + sci_observtn)\n",
    "    uncal_dir = os.path.join(sci_dir, 'uncal')\n",
    "\n",
    "    # Ensure filepaths for input data exist\n",
    "    if not os.path.exists(uncal_dir):\n",
    "        os.makedirs(uncal_dir)\n",
    "        \n",
    "    # Create directory if it does not exist\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.mkdir(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674a8b8",
   "metadata": {},
   "source": [
    "Identify list of science (SCI) uncalibrated files associated with visits.\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Work one filter at a time, so that we can more easily filter by detector and keep only the module A files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b22375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of observation IDs for the specified demo program\n",
    "if demo_mode:\n",
    "    # Science data\n",
    "    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/IMAGE\"],\n",
    "                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n",
    "                                                   filters=['F200W'],  # Data for Specific Filter\n",
    "                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa123f1-be6a-4be8-8e6d-daffc6514098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_obs_id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the list of visits into a list of uncalibrated data files\n",
    "if demo_mode:\n",
    "    # Define types of files to select\n",
    "    file_dict = {'uncal': {'product_type': 'SCIENCE',\n",
    "                           'productSubGroupDescription': 'UNCAL',\n",
    "                           'calib_level': [1]}}\n",
    "\n",
    "    # Science files\n",
    "    sci_files_to_download = []\n",
    "    # Loop over visits identifying uncalibrated files that are associated\n",
    "    # with them\n",
    "    for exposure in (sci_obs_id_table):\n",
    "        products = Observations.get_product_list(exposure)\n",
    "        for filetype, query_dict in file_dict.items():\n",
    "            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n",
    "                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                             calib_level=query_dict['calib_level'])\n",
    "            sci_files_to_download.extend(filtered_products['dataURI'])\n",
    "\n",
    "    # To limit data volume, keep only files from visit 002, dithers 1 and 2, and only A-module\n",
    "    sw_sci_files_to_download = [fname for fname in sci_files_to_download if 'jw02739001002_02105' in fname and \\\n",
    "                                'nrca' in fname and ('00001' in fname or '00002' in fname)]\n",
    "    sw_sci_files_to_download = sorted(sw_sci_files_to_download)\n",
    "    print(f\"Science files selected for downloading: {len(sw_sci_files_to_download)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1e7d5-4f12-47f0-b43e-764c37943644",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_sci_files_to_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add251e-56ed-44ba-85a6-db0a4d55588c",
   "metadata": {},
   "source": [
    "Now repeat the process for the F444W data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809aad0-a5f2-47ce-b813-3adb5888d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of observation IDs for the specified demo program\n",
    "if demo_mode:\n",
    "    # Science data\n",
    "    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/IMAGE\"],\n",
    "                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n",
    "                                                   filters=['F444W'],  # Data for Specific Filter\n",
    "                                                   obs_id=['jw' + program + '-o' + sci_observtn + '*']\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ef61a-4b6c-4aa9-b5c6-4051b56a4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_obs_id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8b8a4-c271-49ac-be28-228fc25891ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the list of visits into a list of uncalibrated data files\n",
    "if demo_mode:\n",
    "    # Define types of files to select\n",
    "    file_dict = {'uncal': {'product_type': 'SCIENCE',\n",
    "                           'productSubGroupDescription': 'UNCAL',\n",
    "                           'calib_level': [1]}}\n",
    "\n",
    "    # Science files\n",
    "    sci_files_to_download = []\n",
    "    # Loop over visits identifying uncalibrated files that are associated\n",
    "    # with them\n",
    "    for exposure in (sci_obs_id_table):\n",
    "        products = Observations.get_product_list(exposure)\n",
    "        for filetype, query_dict in file_dict.items():\n",
    "            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n",
    "                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                             calib_level=query_dict['calib_level'])\n",
    "            sci_files_to_download.extend(filtered_products['dataURI'])\n",
    "\n",
    "    # To limit data volume, keep only files from visit 002, dithers 1 and 2, and only A-module\n",
    "    lw_sci_files_to_download = [fname for fname in sci_files_to_download if 'jw02739001002_02105' in fname and \\\n",
    "                                'nrca' in fname]\n",
    "    lw_sci_files_to_download = sorted(lw_sci_files_to_download)\n",
    "    print(f\"Science files selected for downloading: {len(lw_sci_files_to_download)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad7360-0456-430e-9f85-8e46e49e689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_sci_files_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0986865-907b-473b-8524-93e36c4564ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_files_to_download = sw_sci_files_to_download + lw_sci_files_to_download\n",
    "sci_files_to_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a54be",
   "metadata": {},
   "source": [
    "Download all the uncal files and place them into the appropriate\n",
    "directories.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Warning: If this notebook is halted during this step the downloaded file\n",
    "may be incomplete, and cause crashes later on!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fa682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the demo data if it does not already exist\n",
    "if demo_mode:\n",
    "    for filename in sci_files_to_download:\n",
    "        sci_manifest = Observations.download_file(filename,\n",
    "                                                  local_path=os.path.join(uncal_dir, Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c51254-6295-4f98-bc25-d07300e0d8f4",
   "metadata": {},
   "source": [
    "<a id='Directory-Setup'></a>\n",
    "## 4. Directory Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2740f-925d-4139-93f7-9f00cb9820b8",
   "metadata": {},
   "source": [
    "------------------\n",
    "Set up detailed paths to input/output stages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbedc3-fbe3-4c56-ad18-85b5d0c7d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output subdirectories to keep science data products organized\n",
    "uncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n",
    "det1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n",
    "image2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\n",
    "image3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not\n",
    "# create them\n",
    "if not os.path.exists(det1_dir):\n",
    "    os.makedirs(det1_dir)\n",
    "if not os.path.exists(image2_dir):\n",
    "    os.makedirs(image2_dir)\n",
    "if not os.path.exists(image3_dir):\n",
    "    os.makedirs(image3_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8e6a7-433d-4e5b-a832-46f0bc96a0fe",
   "metadata": {},
   "source": [
    "Look at the first file to determine exposure parameters and practice using\n",
    "JWST datamodels¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767a7fa-50cb-4411-8aef-a32b7fde8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n",
    "\n",
    "# print file name\n",
    "sw_uncal_files = [uncfile for uncfile in uncal_files if 'long' not in uncfile]\n",
    "lw_uncal_files = [uncfile for uncfile in uncal_files if 'long' in uncfile]\n",
    "\n",
    "# Open file as JWST datamodel\n",
    "sw_examine = datamodels.open(sw_uncal_files[0])\n",
    "lw_examine = datamodels.open(lw_uncal_files[0])\n",
    "\n",
    "meta_check = Table()\n",
    "meta_check['Instrument'] = [sw_examine.meta.instrument.name, lw_examine.meta.instrument.name]\n",
    "meta_check['Filter'] = [sw_examine.meta.instrument.filter, lw_examine.meta.instrument.filter]\n",
    "meta_check['Pupil'] = [sw_examine.meta.instrument.pupil, lw_examine.meta.instrument.pupil]\n",
    "meta_check['Number of Integrations'] = [sw_examine.meta.exposure.nints, lw_examine.meta.exposure.nints]\n",
    "meta_check['Number of Groups'] = [sw_examine.meta.exposure.ngroups, lw_examine.meta.exposure.ngroups]\n",
    "meta_check['Readout Pattern'] = [sw_examine.meta.exposure.readpatt, lw_examine.meta.exposure.readpatt]\n",
    "meta_check['Dither position number'] = [sw_examine.meta.dither.position_number, lw_examine.meta.dither.position_number]\n",
    "\n",
    "# Print out exposure info\n",
    "meta_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469a648-9bb1-40f9-9f8b-fb3a29bc5c7f",
   "metadata": {},
   "source": [
    "The table above shows basic exposure information from the first shortwave as well as the first longwave file. When using\n",
    "the demo data, we confirm that the data file is for the NIRCam instrument\n",
    "using the `F200W` and `F444W` filters in the [Filter Wheel](https://jwst-docs.stsci.edu/jwst-near-infrared-camera/nircam-instrumentation/nircam-pupil-and-filter-wheels)\n",
    "crossed with the `CLEAR` filter in the Pupil Wheel. This observation uses\n",
    "the [`BRIGHT1` readout pattern](https://jwst-docs.stsci.edu/jwst-near-infrared-camera/nircam-instrumentation/nircam-detector-overview/nircam-detector-readout-patterns),\n",
    "8 groups per integration, and 1 integration per exposure. This data file\n",
    "is the 1st dither position in this exposure sequence. For more information\n",
    "about how JWST exposures are defined by up-the-ramp sampling, see the\n",
    "[Understanding Exposure Times JDox article](https://jwst-docs.stsci.edu/understanding-exposure-times).\n",
    "\n",
    "This metadata will be the same for all exposures in this observation other\n",
    "than the dither position number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843ff7f-58b6-4294-bfaa-606c29abc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e28e0-a63f-4790-b8a0-3ad4bff5a167",
   "metadata": {},
   "source": [
    "<a id='Detector1-Pipeline'></a>\n",
    "## 5. Detector1 Pipeline\n",
    "Run the datasets through the\n",
    "[Detector1](https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline-overview/stages-of-jwst-data-processing/calwebb_detector1)\n",
    "stage of the pipeline to apply detector level calibrations and create a\n",
    "countrate data product where slopes are fitted to the integration ramps.\n",
    "These `*_rate.fits` products are 2D (nrows x ncols), averaged over all\n",
    "integrations. 3D countrate data products (`*_rateints.fits`) are also\n",
    "created (nintegrations x nrows x ncols) which have the fitted ramp slopes\n",
    "for each integration.\n",
    "\n",
    "By default, all steps in the Detector1 stage of the pipeline are run for\n",
    "NIRCam except: the `ipc` correction step and the `gain_scale` step. Note\n",
    "that the [`persistence` step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/persistence/description.html)\n",
    "has been turned off by default starting with CRDS context jwst_1264.pmap.\n",
    "This step does not automatically correct the science data for persistence.\n",
    "The `persistence` step creates a `*_trapsfilled.fits` file which is a model\n",
    "that records the number of traps filled at each pixel at the end of an exposure.\n",
    "This file would be used as an input to the `persistence` step, via the `input_trapsfilled`\n",
    "argument, to correct the subsequent science exposure for persistence. Since persistence\n",
    "is not well calibrated for NIRCam, the step has been turned off in order to speed up\n",
    "calibration and to not create empty `*_trapsfilled.fits` files. This step\n",
    "can be turned on when running the pipeline in Python by doing:\n",
    "```\n",
    "rate_result = Detector1Pipeline.call(uncal,steps={'persistence': {'skip': False}})\n",
    "```\n",
    "or as indicated in the cell bellow using a dictionary.\n",
    "\n",
    "As of CRDS context `jwst_1155.pmap` and later, the \n",
    "[`jump` step](https://jwst-pipeline.readthedocs.io/en/latest/api/jwst.jump.JumpStep.html)\n",
    "of the `DETECTOR1` stage of the pipeline will remove signal associated\n",
    "with [snowballs](https://jwst-docs.stsci.edu/known-issues-with-jwst-data/shower-and-snowball-artifacts)\n",
    "in the NIRCam imaging mode. This correction is turned on using the parameter\n",
    "`expand_large_events=True`. This and other parameters related to the snowball correction\n",
    "are specified in the `pars-jumpstep` parameter reference file. Users may wish to alter\n",
    "parameters to optimize removal of snowball residuals. Available parameters are discussed\n",
    "in the [Detection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023)](https://www.stsci.edu/files/live/sites/www/files/home/jwst/documentation/technical-documents/_documents/JWST-STScI-008545.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ee58-b424-4bd6-973b-88fd081b81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Detector1 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "det1dict = {}\n",
    "det1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\n",
    "det1dict['ipc'], det1dict['superbias'], det1dict['refpix'] = {}, {}, {}\n",
    "det1dict['linearity'], det1dict['persistence'], det1dict['dark_current'], = {}, {}, {}\n",
    "det1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}\n",
    "det1dict['gain_scale'] = {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped\n",
    "# skipping the persistence step\n",
    "det1dict['persistence']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n",
    "#det1dict['saturation']['override_saturation'] = 'myfile.fits' # Saturation\n",
    "#det1dict['reset']['override_reset'] = 'myfile.fits' # Reset\n",
    "#det1dict['linearity']['override_linearity'] = 'myfile.fits' # Linearity\n",
    "#det1dict['rscd']['override_rscd'] = 'myfile.fits' # RSCD\n",
    "#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n",
    "#det1dict['jump']['override_gain'] = 'myfile.fits' # Gain used by jump step\n",
    "#det1dict['ramp_fit']['override_gain'] = 'myfile.fits' # Gain used by ramp fitting step\n",
    "#det1dict['jump']['override_readnoise'] = 'myfile.fits' # Read noise used by jump step\n",
    "#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits' # Read noise used by ramp fitting step\n",
    "\n",
    "# Turn on multi-core processing (This is off by default). Choose what fraction\n",
    "# of cores to use (quarter, half, all, or an integer number)\n",
    "det1dict['jump']['maximum_cores'] = 'half'\n",
    "\n",
    "# Explicitly turn on snowball correction. (Even though it is on by default)\n",
    "det1dict['jump']['expand_large_events'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f107b-5f80-4674-bc34-2d88791e4409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Detector1 stage of pipeline, specifying:\n",
    "# output directory to save *_rate.fits files\n",
    "# save_results flag set to True so the rate files are saved\n",
    "\n",
    "if dodet1:\n",
    "    for uncal in uncal_files:\n",
    "        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True,)\n",
    "else:\n",
    "    print('Skipping Detector1 processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc2b48-7ec7-4b59-b3ee-2dfdf0782c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime for Detector1: {time1 - time0:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5520a-6097-482b-b3e0-a6bf94cf7af3",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "Identify `*_rate.fits` files and verify which pipeline steps were run and\n",
    "which calibration reference files were applied.\n",
    "\n",
    "The header contains information about which calibration steps were\n",
    "completed and skipped and which reference files were used to process the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c122766-a545-4042-93e8-f68c18f62fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rate files\n",
    "rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rate.fits')))\n",
    "\n",
    "# Read in file as datamodel\n",
    "rate_f = datamodels.open(rate_files[0])\n",
    "\n",
    "# Check which steps were run\n",
    "rate_f.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2396cc-939f-44a6-878c-b33955796da8",
   "metadata": {},
   "source": [
    "Check which reference files were used to calibrate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525e133-d875-4ea7-9552-d7f0df05747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350808ee-9579-4cb5-8f02-a74904c91449",
   "metadata": {},
   "source": [
    "<a id='Image2-Pipeline'></a>\n",
    "## 6. Image2 Pipeline \n",
    "\n",
    "In the [Image2 stage of the pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html),\n",
    "calibrated unrectified data products are created (`*_cal.fits` or\n",
    "`*_calints.fits` files, depending on whether the input files are\n",
    "`*_rate.fits` or `*_rateints.fits`). \n",
    "\n",
    "In this pipeline processing stage, the [world coordinate system (WCS)](https://jwst-pipeline.readthedocs.io/en/latest/jwst/assign_wcs/index.html#assign-wcs-step)\n",
    "is assigned, the data are [flat fielded](https://jwst-pipeline.readthedocs.io/en/latest/jwst/flatfield/index.html#flatfield-step),\n",
    "and a [photometric calibration](https://jwst-pipeline.readthedocs.io/en/latest/jwst/photom/index.html#photom-step)\n",
    "is applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n",
    "\n",
    "By default, the [background subtraction step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/background_step/index.html#background-step)\n",
    "and the [resampling step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/index.html#resample-step)\n",
    "are turned off for NIRCam. The background\n",
    "subtraction is turned off since there is no background template for the\n",
    "imaging mode and the local background is subtracted as part of the photometry\n",
    "perfoemd in the source catalog step in the `Image3` pipeline. \n",
    "\n",
    "The\n",
    "resampling step occurs during the `Image3` stage by default. \n",
    "\n",
    "While the\n",
    "resampling step can be run on individual images in the `Image2` stage, e.g., \n",
    "to prepare for generating a source catalog for each image, the default behavior\n",
    "is to run the step only in the `Image3` stage, where multiple images are \n",
    "combined into a final mosaic after the [outlier detection step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/index.html)\n",
    "flags bad pixels.\n",
    "\n",
    "To turn on the resampling step in the `Image2` stage, uncomment the line in the\n",
    "dicitionary below which sets `image2dict['resample']['skip'] = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a091817-7a3c-4a60-a914-f9ac54d36e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_image2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00fda2-a7c0-445a-bf23-0d9b4f050419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Image2 pipeline should be configured.\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "image2dict = {}\n",
    "image2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\n",
    "image2dict['photom'], image2dict['resample'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#image2dict['resample']['skip'] = False\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf' # Imager filter offsets (ASDF file)\n",
    "#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf' # Wavelength channel mapping (ASDF file)\n",
    "#image2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n",
    "#image2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247170cd-a3ee-4d9d-b8b3-f930727f8abc",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cd4e6-cc38-4e26-8e8b-7fb143856940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstring = os.path.join(det1_dir, 'jw*rate.fits')  # Use files from the detector1 output folder\n",
    "rate_files = sorted(glob.glob(sstring))\n",
    "rate_files = [os.path.abspath(fname) for fname in rate_files]\n",
    "\n",
    "print(f\"Found  {len(rate_files)} science files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc9789-9048-4c2f-826d-69c36fcd1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d916e5-dd5d-472d-9aff-b2b4c86decf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Image2 stage of pipeline, specifying:\n",
    "# output directory to save *_cal.fits files\n",
    "# save_results flag set to True so the rate files are saved\n",
    "\n",
    "if doimage2:\n",
    "    for rate in rate_files:\n",
    "        cal_result = Image2Pipeline.call(rate, output_dir=image2_dir, steps=image2dict, save_results=True)\n",
    "else:\n",
    "    print(\"Skipping Image2 processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58b94d-e1d7-4b73-b598-756c99d81174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57b7d0-95ef-4227-b730-6f54a3eaaa16",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27390bbd-ae2d-49e7-977a-59d3765c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify *_cal.fits files\n",
    "cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_cal.fits')))\n",
    "\n",
    "cal_f = datamodels.open(cal_files[0])\n",
    "\n",
    "# Check which steps were run:\n",
    "cal_f.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77293ab-4eaa-4ebd-9f9b-bef8f6a2300f",
   "metadata": {},
   "source": [
    "Check which reference files were used to calibrate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544744b-804e-4583-8311-e47b5e16c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbb244-7af9-4cbf-90d9-08598378c16a",
   "metadata": {},
   "source": [
    "<a id='Image3-Pipeline'></a>\n",
    "## 7. Image3 Pipeline\n",
    "\n",
    "In the [Image3 stage of the pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html), the individual `*_cal.fits` files for each filter are combined to one single distortion corrected image. Unlike the previous stages, we must run the `Image3` stage separately for the files from each filter as well as channel (i.e. shortwave vs longwave).\n",
    "\n",
    "First, we need to create [Associations](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/overview.html), to inform the pipeline which files are linked together for each filter.\n",
    "\n",
    "By default, the `Image3` stage of the pipeline performs the following steps on NIRCam data: \n",
    "- [tweakreg](https://jwst-pipeline.readthedocs.io/en/latest/jwst/tweakreg/index.html#tweakreg-step) - creates source catalogs of pointlike sources for each input image. The source catalog for each input image is compared to each other to derive coordinate transforms to align the images relative to each other.\n",
    "   - `tweakreg` has many [input parameters](https://jwst-pipeline.readthedocs.io/en/latest/jwst/tweakreg/README.html#step-arguments) that can be adjusted to improve the image alignment in cases where the default values do not perform well.\n",
    "   - One tweakreg parameter that is not set by default but can be very useful is `abs_refcat`. When this parameter is set to `GAIADR3`, the tweakreg step performs an absolute astrometric correction of the data using the GAIA data release 3 catalog. In cases where multiple unsaturated GAIA stars are present in the input images, this can improve the absolute astrometric alignment. However, in sparse or very crowded fields, this can potentially result in poor performance, so users are encouraged to check astrometric accuracy and revisit this step if necessary.\n",
    "   - As of pipeline version 1.14.0, the default source finding algorithm in the `tweakreg step` is `IRAFStarFinder`. Other options include `DAOStarFinder`, whose results are not as good in cases where the PSF is undersampled, such as in the blue filters of the NIRCam shortwave channel, and [photutils segmentation SourceFinder](https://photutils.readthedocs.io/en/latest/api/photutils.segmentation.SourceFinder.html), which does not assume sources are point-like.\n",
    "- [skymatch](https://jwst-pipeline.readthedocs.io/en/latest/jwst/skymatch/index.html#skymatch-step) - measures the background level from the sky to use as input into the subsequent `outlier detection` and `resample` steps.\n",
    "- [outlier detection](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/index.html#outlier-detection-step) - flags any remaining cosmic rays, bad pixels, or other artifacts not already flagged during the `DETECTOR1` stage of the pipeline, using all input images to create a median image so that outliers in individual images can be identified.\n",
    "- [resample](https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/index.html#resample-step) - resamples each input image based on its WCS and distortion information and creates a single undistorted image.\n",
    "- [source catalog](https://jwst-pipeline.readthedocs.io/en/latest/jwst/source_catalog/index.html#source-catalog-step) - creates a catalog of detected sources along with photometric results and morphologies (i.e., point-like vs extended). These catalogs are generally useful for quick checks, but optimization is likely needed for specific science cases. Users may wish to experiment with changing the `snr_threshold` and `deblend` options. Modifications to the following parameters will not significantly improve data quality and it is advised to keep them at their default values: `aperture_ee1`, `aperture_ee2`, `aperture_ee3`, `ci1_star_threshold`, `ci2_star_threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e81dc9-78dd-4bba-879c-9dfa2a4da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_image3 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159e63d-3c89-44ef-9a43-caaccd1abb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Image3 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "image3dict = {}\n",
    "image3dict['assign_mtwcs'], image3dict['tweakreg'], image3dict['skymatch'] = {}, {}, {}\n",
    "image3dict['outlier_detection'], image3dict['resample'], image3dict['source_catalog'] = {}, {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#image3dict['outlier_detection']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#image3dict['source_catalog']['override_apcorr'] = 'myfile.fits'  # Aperture correction parameters\n",
    "#image3dict['source_catalog']['override_abvegaoffset'] = 'myfile.asdf' # Data to convert from AB to Vega magnitudes (ASDF file)\n",
    "\n",
    "# Turn on alignment to GAIA in the tweakreg step\n",
    "image3dict['tweakreg']['abs_refcat'] = 'GAIADR3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10da872-21ae-46c2-a3b1-f9cdefae3b36",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths.\n",
    "Keep files for the two filters separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b5b47-62e9-4593-abc4-7ec630492e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science Files need the cal.fits files\n",
    "sw_sstring = os.path.join(image2_dir, 'jw*nrc??_cal.fits')     # shortwave files. Detectors a1-a4, b1-b4\n",
    "lw_sstring = os.path.join(image2_dir, 'jw*nrc*long_cal.fits')  # longwave files. Detectors along, blong \n",
    "\n",
    "sw_cal_files = sorted(glob.glob(sw_sstring))\n",
    "lw_cal_files = sorted(glob.glob(lw_sstring))\n",
    "\n",
    "# Expand the relative paths into absolute paths\n",
    "sw_cal_files = [os.path.abspath(fname) for fname in sw_cal_files]\n",
    "lw_cal_files = [os.path.abspath(fname) for fname in lw_cal_files]\n",
    "\n",
    "print(f'Found {len(sw_cal_files)} shortwave science files to process')\n",
    "print(f'Found {len(lw_cal_files)} longwave science files to process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6550a4a-f924-410b-a945-effcef431e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_cal_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712cd88-1a88-4557-a86e-8fa78bd91217",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_cal_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cb6f5-44a1-4f28-95dc-b23a97451465",
   "metadata": {},
   "source": [
    "### Create Association File\n",
    "\n",
    "An association file lists the files to calibrate together in `Stage 3` of the pipeline. Note that association files are available for download from MAST, with filenames of `*_asn.json`. Here we show how to create an association file to point to the data products created in the steps above. This is useful in cases where you want to work with a set of data that is different than that in the association files from MAST.\n",
    "\n",
    "Note that the output products will have a rootname that is specified by the `product_name` in the association file. For this tutorial, the rootnames of the output products will be `image3_f200w` and `image3_f444w`.   XXXXXXXmake product names generic rather than filter specific???XXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31f80f-8d7b-45ae-8537-15d0208637df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Level 3 Associations\n",
    "if doimage3:\n",
    "    sw_product_name = 'image3_sw'\n",
    "    sw_association = asn_from_list.asn_from_list(sw_cal_files,\n",
    "                                                 rule=DMS_Level3_Base,\n",
    "                                                 product_name=sw_product_name)\n",
    "    \n",
    "    sw_association.data['asn_type'] = 'image3'\n",
    "    sw_association.data['program'] = program\n",
    "    \n",
    "    # Format association as .json file\n",
    "    sw_asn_filename, sw_serialized = sw_association.dump(format=\"json\")\n",
    "\n",
    "    # Write out association file\n",
    "    sw_association_im3 = os.path.join(sci_dir, sw_asn_filename)\n",
    "    with open(sw_association_im3, \"w\") as fd:\n",
    "        fd.write(sw_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba8977-dc92-4aea-b245-bb2554a41612",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doimage3:\n",
    "    lw_product_name = 'image3_lw'\n",
    "    lw_association = asn_from_list.asn_from_list(lw_cal_files,\n",
    "                                                 rule=DMS_Level3_Base,\n",
    "                                                 product_name=lw_product_name)\n",
    "    \n",
    "    lw_association.data['asn_type'] = 'image3'\n",
    "    lw_association.data['program'] = program\n",
    "    \n",
    "    # Format association as .json file\n",
    "    lw_asn_filename, lw_serialized = lw_association.dump(format=\"json\")\n",
    "\n",
    "    # Write out association file. Note that you can use your own filename in\n",
    "    # place of lw_asn_filename and everything will still work.\n",
    "    lw_association_im3 = os.path.join(sci_dir, lw_asn_filename)\n",
    "    with open(lw_association_im3, \"w\") as fd:\n",
    "        fd.write(lw_serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cad5b-e5a7-473e-8583-ad12cda55fa4",
   "metadata": {},
   "source": [
    "### Run Image3 stage of the pipeline\n",
    "\n",
    "Given the grouped exposures in the association file, the `Image3` stage of the pipeline will produce:\n",
    "- a `*_cr.fits` file produced by the `outlier_detection` step, where the `DQ` array marks the pixels flagged as outliers.\n",
    "- a final combined, rectified image with name `*_i2d.fits`,\n",
    "- a source catalog with name `*_cat.ecsv`,\n",
    "- a segmentation map file (`*_segm.fits`) which has integer values at the pixel locations where a source is detected where the pixel values match the source ID number in the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cebfd8-a650-41a3-8ff0-a8fd43e079d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Stage 3\n",
    "\n",
    "if doimage3:\n",
    "    sw_i2d_result = Image3Pipeline.call(sw_association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\n",
    "    lw_i2d_result = Image3Pipeline.call(lw_association_im3, output_dir=image3_dir, steps=image3dict, save_results=True)\n",
    "else:\n",
    "    print('Skipping Spec3 processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d2c65-4614-4592-aa67-daa2de985013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Image3: {time1 - time_image3:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb6c40-fbb8-4226-b620-64b0c02c8ceb",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754530a-d4e2-493b-bf8b-bf8d1ad08770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify *_i2d file and open as datamodel\n",
    "sw_i2d_file = os.path.join(image3_dir, f'{sw_product_name}_i2d.fits')\n",
    "lw_i2d_file = os.path.join(image3_dir, f'{lw_product_name}_i2d.fits')\n",
    "\n",
    "i2d_sw_model = datamodels.open(sw_i2d_file)\n",
    "i2d_lw_model = datamodels.open(lw_i2d_file)\n",
    "\n",
    "# Check which steps were run\n",
    "i2d_sw_model.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c5280-69a5-4796-b78f-724078a94d2b",
   "metadata": {},
   "source": [
    "Check which reference files were used to calibrate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb0842-cc95-42d5-8852-593b85032c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2d_sw_model.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be5421-7fc8-4d96-b2cd-2484f294e082",
   "metadata": {},
   "source": [
    "<a id='Visualize-the-resampled-images'></a>\n",
    "## 8. Visualize the resampled images\n",
    "\n",
    "We are using the [Imviz tool](https://jdaviz.readthedocs.io/en/latest/imviz/index.html) within the `jdaviz` package to visualize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1ed63-0bed-412b-ab04-54caa7d61bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Imviz instance and set up default viewer for the F200W data\n",
    "imviz_sw_i2d = Imviz()\n",
    "viewer_sw_i2d = imviz_sw_i2d.default_viewer\n",
    "\n",
    "# Read in the science array for our visualization dataset:\n",
    "i2d_sw_science = i2d_sw_model.data\n",
    "\n",
    "# Load the dataset into Imviz\n",
    "imviz_sw_i2d.load_data(i2d_sw_science)\n",
    "\n",
    "# Visualize the dataset:\n",
    "imviz_sw_i2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22a117-e4cf-4d2f-9fec-f52545c8aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_sw_i2d.stretch = 'sqrt'\n",
    "viewer_sw_i2d.set_colormap('Viridis')\n",
    "viewer_sw_i2d.cuts = '95%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e57c7-3a29-455e-8a94-627862c00fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Imviz instance and set up default viewer for the F444W data\n",
    "imviz_lw_i2d = Imviz()\n",
    "viewer_lw_i2d = imviz_lw_i2d.default_viewer\n",
    "\n",
    "# Read in the science array for our visualization dataset:\n",
    "i2d_lw_science = i2d_lw_model.data\n",
    "\n",
    "# Load the dataset into Imviz\n",
    "imviz_lw_i2d.load_data(i2d_lw_science)\n",
    "\n",
    "# Visualize the dataset:\n",
    "imviz_lw_i2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0f7b4-129e-4277-b1b2-608850a6262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_lw_i2d.stretch = 'sqrt'\n",
    "viewer_lw_i2d.set_colormap('Viridis')\n",
    "viewer_lw_i2d.cuts = '95%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018733eb-07ec-44a4-a5a7-d6d2f27d193a",
   "metadata": {},
   "source": [
    "## <a id='detections'>Visualize Detected Sources</a>\n",
    "Using the source catalogs created by the `IMAGE3` stage of the pipeline, mark the detected sources, using different markers for point sources and extended sources. The source catalogs are saved in `image3/image3_f200w_cat.ecsv` and `image3/image3_f444w_cat.ecsv`. This time, we will provide the i2d filename to the `imviz` `load_data` function, rather than just the array of pixel values. This way, `imviz` will be able to make use of the World Coordinate System (WCS) in the file. This will allow the sources in the source catalog to be accurately marked in the display."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6ee55-f940-4be3-96c9-114bc83eb784",
   "metadata": {},
   "source": [
    "### Read in catalog file and identify point/extended sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32235fdc-4ec2-42e6-89e7-b9f62824e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_catalog_file = sw_i2d_file.replace('i2d.fits', 'cat.ecsv')\n",
    "lw_catalog_file = lw_i2d_file.replace('i2d.fits', 'cat.ecsv')\n",
    "\n",
    "sw_catalog = Table.read(sw_catalog_file)\n",
    "lw_catalog = Table.read(lw_catalog_file)\n",
    "\n",
    "# To identify point/extended sources, use the 'is_extended' column in the source catalog\n",
    "sw_pt_src, = np.where(~sw_catalog['is_extended'])\n",
    "sw_ext_src, = np.where(sw_catalog['is_extended'])\n",
    "lw_pt_src, = np.where(~lw_catalog['is_extended'])\n",
    "lw_ext_src, = np.where(lw_catalog['is_extended'])\n",
    "\n",
    "# Define coordinates of point and extended sources\n",
    "sw_pt_coord = Table({'coord': [SkyCoord(ra=sw_catalog['sky_centroid'][sw_pt_src].ra,\n",
    "                                     dec=sw_catalog['sky_centroid'][sw_pt_src].dec)]})\n",
    "sw_ext_coord = Table({'coord': [SkyCoord(ra=sw_catalog['sky_centroid'][sw_ext_src].ra,\n",
    "                                      dec=sw_catalog['sky_centroid'][sw_ext_src].dec)]})\n",
    "lw_pt_coord = Table({'coord': [SkyCoord(ra=lw_catalog['sky_centroid'][lw_pt_src].ra,\n",
    "                                     dec=lw_catalog['sky_centroid'][lw_pt_src].dec)]})\n",
    "lw_ext_coord = Table({'coord': [SkyCoord(ra=lw_catalog['sky_centroid'][lw_ext_src].ra,\n",
    "                                      dec=lw_catalog['sky_centroid'][lw_ext_src].dec)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e9069-375d-431b-bbfb-e84e6cefc2d4",
   "metadata": {},
   "source": [
    "### Mark the extended and point sources on the images\n",
    "\n",
    "Display the image with sources indicated by circles. Point sources will be marked by small pink circles and extended sources will be marked by white circles. Looking at the entire mosaic, there are so many sources found that it's hard to see much of anything. To get a clearer view, try zooming in on various areas using the magnifying glass icon on the banner immediately above the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64860785-66a2-4624-acdc-031f6b0ab18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SW i2d file to Imviz\n",
    "imviz_sw_cat = Imviz()\n",
    "viewer_sw_cat = imviz_sw_cat.default_viewer\n",
    "imviz_sw_cat.load_data(sw_i2d_file)\n",
    "\n",
    "# Adjust settings for viewer\n",
    "viewer_sw_cat.stretch = 'sqrt'\n",
    "viewer_sw_cat.set_colormap('Viridis')\n",
    "viewer_sw_cat.cuts = '95%'\n",
    "\n",
    "imviz_sw_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8f619-3807-44d1-a8d9-fbf41abb5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add marker for point sources:\n",
    "viewer_sw_cat.marker = {'color': 'pink', 'markersize': 50, 'fill': False}\n",
    "\n",
    "viewer_sw_cat.add_markers(sw_pt_coord, use_skycoord=True, marker_name='point_sources')\n",
    "\n",
    "# Add marker for extended sources:\n",
    "viewer_sw_cat.marker = {'color': 'white', 'markersize': 100, 'fill': False}\n",
    "\n",
    "viewer_sw_cat.add_markers(sw_ext_coord, use_skycoord=True, marker_name='extended_sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da0dd5-bd26-425f-8d26-5d7c9d109755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat using the LW file\n",
    "imviz_lw_cat = Imviz()\n",
    "viewer_lw_cat = imviz_lw_cat.default_viewer\n",
    "imviz_lw_cat.load_data(lw_i2d_file)\n",
    "\n",
    "# Adjust settings for viewer\n",
    "viewer_lw_cat.stretch = 'sqrt'\n",
    "viewer_lw_cat.set_colormap('Viridis')\n",
    "viewer_lw_cat.cuts = '95%'\n",
    "\n",
    "imviz_lw_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1aa48-1104-416b-aa48-e4247498d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add marker for point sources:\n",
    "viewer_lw_cat.marker = {'color': 'pink', 'markersize': 50, 'fill': False}\n",
    "\n",
    "viewer_lw_cat.add_markers(lw_pt_coord, use_skycoord=True, marker_name='point_sources')\n",
    "\n",
    "# Add marker for extended sources:\n",
    "viewer_lw_cat.marker = {'color': 'white', 'markersize': 100, 'fill': False}\n",
    "\n",
    "viewer_lw_cat.add_markers(lw_ext_coord, use_skycoord=True, marker_name='extended_sources')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde191a9-cc88-4584-8524-780d245b469f",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_footer.png' alt=\"stsci_logo\" width=\"400px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
